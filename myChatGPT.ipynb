{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from  torch.nn import functional as F\n",
    "torch.manual_seed(1337)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1115394\n"
     ]
    }
   ],
   "source": [
    "with open(\"input.txt\", \"r\", encoding = \"utf-8\") as f:\n",
    "    text=f.read()\n",
    "print(len(text))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n"
     ]
    }
   ],
   "source": [
    "vocab = list(set(text))\n",
    "vocab.sort()\n",
    "print(\"\".join(vocab))\n",
    "vocab_size = len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[46, 47, 1, 46, 53] hi ho\n"
     ]
    }
   ],
   "source": [
    "#encoder\n",
    "ctoi = { vocab[i]:i for i in range(len(vocab))}\n",
    "itoc = { i:vocab[i] for i in range(len(vocab))}\n",
    "def encode(s): return [ ctoi[i] for i in s]\n",
    "def decode(t): return \"\".join([ itoc[i] for i in t])\n",
    "\n",
    "tokens = encode(\"hi ho\")\n",
    "s = decode(tokens)\n",
    "print(tokens, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18, 47, 56, 57, 58, 1, 15, 47, 58, 47, 64, 43, 52, 10, 0, 14, 43, 44, 53, 56]\n",
      "First Citizen:\n",
      "Befor\n"
     ]
    }
   ],
   "source": [
    "tokens = encode(text)\n",
    "print(tokens[:20])\n",
    "print(decode(tokens[:20]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.tensor(tokens, dtype=torch.long, device = device)\n",
    "n = int(0.9*len(data))\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[53, 59,  6,  1, 58, 56, 47, 40],\n",
      "        [49, 43, 43, 54,  1, 47, 58,  1],\n",
      "        [13, 52, 45, 43, 50, 53,  8,  0],\n",
      "        [ 1, 39,  1, 46, 53, 59, 57, 43]], device='cuda:0')\n",
      "tensor([[59,  6,  1, 58, 56, 47, 40, 59],\n",
      "        [43, 43, 54,  1, 47, 58,  1, 58],\n",
      "        [52, 45, 43, 50, 53,  8,  0, 26],\n",
      "        [39,  1, 46, 53, 59, 57, 43,  0]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "def get_batch(data, batch_size = 4, block_size = 8 ):\n",
    "    indices = torch.randint(len(data)-block_size-1, (batch_size,))\n",
    "    x = torch.stack([data[i:i+block_size] for i in indices], dim=0)\n",
    "    y = torch.stack([data[i+1:i+block_size+1] for i in indices], dim=0)\n",
    "    return x,y   \n",
    "\n",
    "x,y =  get_batch(train_data)    \n",
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss(model, dataset):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        total = 0\n",
    "        for i in range(100):   \n",
    "            x,y =  get_batch(train_data, 64, model.get_context_size())    \n",
    "            _, loss = model(x,y)\n",
    "            total += loss\n",
    "        model.train()\n",
    "        return float((total/100).cpu())\n",
    "\n",
    "def train(model, lr, batch_size, iterations, iter_eval):\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=lr)\n",
    "\n",
    "    print(compute_loss(model, train_data), compute_loss(model, val_data))\n",
    "\n",
    "    for it in range(iterations):\n",
    "        x,y =  get_batch(train_data, batch_size, model.get_context_size())    \n",
    "        _, loss = model(x,y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()    \n",
    "        if it % iter_eval == 0:\n",
    "            print(it//iter_eval, compute_loss(model, train_data), compute_loss(model, val_data))\n",
    "        \n",
    "    torch.save(model.state_dict(), f\"./{model.model.name}.pth\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "class Bigram(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = nn.Embedding(vocab_size, vocab_size)\n",
    "        self.name = f\"bigram_{vocab_size}\"\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, model):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "\n",
    "    def forward(self, x, y = None):\n",
    "        p = self.model(x)\n",
    "        if y!=None:\n",
    "            ly = F.one_hot(y, vocab_size).type(torch.float32)\n",
    "            loss = loss_fn(p.permute(0,2,1), ly.permute(0,2,1))\n",
    "        else:\n",
    "            loss = None\n",
    "        return p, loss\n",
    "    \n",
    "    def generate(self, count):\n",
    "        s = torch.zeros((1,1), dtype=torch.long, device = device)\n",
    "        out = s\n",
    "        for i in range(count):\n",
    "            #print(s)\n",
    "            p, _ = self.forward(s)\n",
    "            probs = F.softmax(p[0], dim=1)\n",
    "            s = torch.multinomial(probs,1)\n",
    "            #print(\"sample\", ss)\n",
    "            out = torch.cat([out, s], dim=1)\n",
    "\n",
    "        return decode(out[0].tolist())\n",
    "    \n",
    "    def get_context_size(self):\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "yq$;tfBfROkNdcuwdZZTkOMl;,ertK\n",
      "w:!PLCkMBbeA$3:XaSGJO-3p&M-c?KL3auhpFYVXJFhNNNuhq$OMxv.tbVFYdXlrFZaAeNuw:cPPyREFkHDEZaYJFzyWNuX\n",
      "Yo3&$LMtofBimzLB!!&V!Ox;Kl;l;ZcKe3 ixYeYEFngmi;;lxWvHFGEZEQG EsSXHB;kW3 J\n",
      "4.627649307250977 4.631004810333252\n",
      "0 4.639685153961182 4.63800573348999\n",
      "1 4.330250263214111 4.331907749176025\n",
      "2 4.061417579650879 4.0431013107299805\n",
      "3 3.821509599685669 3.8229637145996094\n",
      "4 3.6014459133148193 3.6163885593414307\n",
      "5 3.44629168510437 3.424192190170288\n",
      "6 3.2874021530151367 3.298607349395752\n",
      "7 3.202650308609009 3.1776974201202393\n",
      "8 3.050213575363159 3.0766634941101074\n",
      "9 2.992992877960205 2.9892590045928955\n",
      "\n",
      "BYGENilerjbouselplind me l.\n",
      "lishe cnchiry:\n",
      "Uug;Mnisspllw y.O:ur n'SIREDmopetelivIEjMPithy wJd mothakllo W,Coo wh VCeiib3MI'Thom bMxWivDThenghim$Fs p-LK3gAY-xT3b\n",
      "\n",
      "ALENxmntcrurt f so;;3QQDLETm:\n",
      "EN,CI ma\n"
     ]
    }
   ],
   "source": [
    "bm = Generator(Bigram()).to(device)\n",
    "print(bm.generate(200))\n",
    "train(bm, lr=1e-3, batch_size=4, iterations=10000, iter_eval=1000)\n",
    "print(bm.generate(200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    def __init__(self, context_size, input_size, output_size):\n",
    "        super().__init__()\n",
    "        # KQV size\n",
    "        self.output_size = output_size\n",
    "        self.key = nn.Linear(input_size, output_size, bias=False)\n",
    "        self.query = nn.Linear(input_size, output_size, bias=False)\n",
    "        self.value = nn.Linear(input_size, output_size, bias=False)\n",
    "\n",
    "        sz = context_size\n",
    "        mask = (torch.triu(torch.ones(sz, sz)) == 1).transpose(0, 1)\n",
    "        mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
    "        self.register_buffer(\"mask\", mask)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        em_key = self.key(x)\n",
    "        em_query = self.query(x)\n",
    "        em_value = self.value(x)\n",
    "\n",
    "        # the attentions matrix must be the size of the context\n",
    "        # as it is in reality an adjacency matrix\n",
    "        att = em_query @ em_key.transpose(-2,-1)\n",
    "\n",
    "        #print (att.shape)\n",
    "\n",
    "        att /= self.output_size ** 0.5\n",
    "\n",
    "        att += self.mask\n",
    "\n",
    "        att = F.softmax(att, dim=-1)\n",
    "        return att @ em_value \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropout=0.1\n",
    "\n",
    "class Block(nn.Module):\n",
    "    def __init__(self, context_size, num_heads, embedding_size):\n",
    "        super().__init__()\n",
    "\n",
    "        self.ln1 = nn.LayerNorm(embedding_size)\n",
    "\n",
    "        self.head = nn.ModuleList( [Attention(context_size, embedding_size, embedding_size//num_heads) for _ in range(num_heads)])\n",
    "        self.linear = nn.Linear(embedding_size, embedding_size)\n",
    "        self.dp1 = nn.Dropout(dropout)\n",
    "        \n",
    "        self.ln2 = nn.LayerNorm(embedding_size)\n",
    "\n",
    "        self.ff = nn.Sequential(\n",
    "            nn.Linear(embedding_size, 4 * embedding_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4 * embedding_size, embedding_size),\n",
    "            nn.Dropout(dropout),\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        lx = self.ln1(x)\n",
    "        x1 = self.linear(torch.cat([head(lx) for head in self.head], dim=-1))\n",
    "        x1 = self.dp1(x1)\n",
    "        x = x + x1\n",
    "        \n",
    "        lx = self.ln2(x)\n",
    "        x2 = self.ff(lx)\n",
    "        x = x + x2\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class ChatGPT(nn.Module):\n",
    "    def __init__(self, context_size, num_blocks, num_heads, embedding_size):\n",
    "        super().__init__()\n",
    "        self.name = f\"gpt_{context_size}_{num_blocks}_{num_heads}_{embedding_size}\"\n",
    "        self.context_size = context_size\n",
    "        pos = torch.arange(0, context_size, dtype=torch.long)\n",
    "        self.register_buffer(\"pos\", pos)\n",
    "\n",
    "        self.tok_embedding = nn.Embedding(vocab_size, embedding_size)\n",
    "        self.pos_embedding = nn.Embedding(context_size, embedding_size)\n",
    "\n",
    "        self.blocks = nn.Sequential( *[Block(context_size, num_heads, embedding_size) for _ in range(num_blocks)])\n",
    "\n",
    "        self.ln = nn.LayerNorm(embedding_size) # final layer norm\n",
    "        self.linear = nn.Linear(embedding_size, vocab_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        te = self.tok_embedding(x)\n",
    "        pe = self.pos_embedding(self.pos)\n",
    "        x = te + pe\n",
    "\n",
    "        x = self.blocks(x)\n",
    "        x = self.ln(x)\n",
    "\n",
    "        x = self.linear(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, model):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "\n",
    "    def forward(self, x, y = None):\n",
    "        p = self.model(x)\n",
    "        if y!=None:\n",
    "            ly = F.one_hot(y, vocab_size).type(torch.float32)\n",
    "            loss = loss_fn(p.permute(0,2,1), ly.permute(0,2,1))\n",
    "        else:\n",
    "            loss = None\n",
    "        return p, loss\n",
    "    \n",
    "    def generate(self, count, str=\" \"):\n",
    "        self.eval()\n",
    "        with torch.no_grad():\n",
    "            s = torch.zeros((1,self.model.context_size), dtype=torch.long).to(device)\n",
    "\n",
    "            prompt = torch.tensor([encode(str)], dtype=torch.long, device = device)\n",
    "            prompt_len = len(str)\n",
    "\n",
    "            s[0, -prompt_len:] = prompt\n",
    "            out = s\n",
    "            for i in range(count):\n",
    "                p, _ = self.forward(out[:,-self.model.context_size:])\n",
    "                probs = F.softmax(p[0], dim=1)\n",
    "                s = torch.multinomial(probs,1)\n",
    "                out = torch.cat([out, s[-1].unsqueeze(1)], dim=1)\n",
    "\n",
    "            return decode(out[0].tolist()[self.model.context_size-prompt_len:])\n",
    "        self.train()\n",
    "\n",
    "    def get_context_size(self):\n",
    "        return self.model.context_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Experiment(context_size = 8, num_blocks = 4, num_heads = 8, embedding_size = 64):\n",
    "    print(\"configuration\", context_size, num_blocks, num_heads, embedding_size)\n",
    "    gen = ChatGPT(context_size, num_blocks, num_heads, embedding_size)\n",
    "    cg = Generator(gen).to(device)\n",
    "    #train(cg, lr=1e-4, iterations=10)\n",
    "    return cg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "configuration 8 4 8 64\n",
      " UUJ$rA!xpD:: x;fDbRaxnxeWGsdGQ3qf3alANY!jtdogKW?':-cj$QN.Sia!nlkCn$x&OqCCxDNsa33 sPPu:KyYTg!D$UQ3ayF;:eDxqQa3x !Ed' an?McW$NfZF,xaKc$3cN&S'MYJ&f-QAc&Y$wxsUX$sf- IR.?'Bp$DUx3&snfcYl$-e\n",
      "qN3an$:bm tfrxJakN.OEYt3-?YXNeOqxowgpffQ&xcnva$bYk,mo-hh.JYDKnxxhkrNx',Ts3MY;KL$a!&-d j'L f?xYXcPadTT$xGxfmUXfk'ZjRxOagfoaqq!UH$f!QWIJ$xxkNroBNzYNWgYysQaefxLPfhfy,$eKVP$:ulczdfjxBXKEz$Dc$xfp cTv:;!!PWYMeDT-cYTfWlvkr,ckxx3.N\n",
      "VObWWfZx,NJmafcxXeaNul ;$Ha?YW:fbgdg'?soQ:-fPxMVflz3FfcBqyf-h!NfHfZ-fg3NUdV:\n",
      "GnxXd$ ;f&IzDkd\n",
      "4.343344211578369 4.34586763381958\n",
      "0 4.325704097747803 4.32121467590332\n",
      "1 3.391835927963257 3.3991169929504395\n",
      "2 3.1427764892578125 3.1494877338409424\n",
      "3 2.9176723957061768 2.9262022972106934\n",
      "4 2.7576820850372314 2.769906759262085\n",
      "5 2.6690285205841064 2.6696863174438477\n",
      "6 2.6053688526153564 2.598721981048584\n",
      "7 2.5632643699645996 2.554905652999878\n",
      "8 2.5135509967803955 2.5118911266326904\n",
      "9 2.476839542388916 2.4772424697875977\n",
      "10 2.442214250564575 2.4460175037384033\n",
      "11 2.423598051071167 2.419424533843994\n",
      "12 2.400937080383301 2.4129600524902344\n",
      "13 2.3842601776123047 2.388460636138916\n",
      "14 2.3601233959198 2.3661139011383057\n",
      "15 2.3506479263305664 2.33829665184021\n",
      "16 2.324392795562744 2.330915689468384\n",
      "17 2.306697130203247 2.3165204524993896\n",
      "18 2.3049705028533936 2.2984018325805664\n",
      "19 2.2846157550811768 2.2794699668884277\n",
      " che wheachs beres ind destNensperr frak,\n",
      "Ay whave litt oy pins eand freaings hit izixcd wasWHehs, wour with kerd niuielt lo o,\n",
      "Ther land, my'd toy;\n",
      "Buve\n",
      "Ytuther er cove ind;\n",
      "Is, leped us shay bedll? to ven cen, rise as inat, toert by whesoutszealed\n",
      "Besenk bris,\n",
      "I IW?N\n",
      "RST:Preand mtesp,\n",
      "Tfordsif hhe mpronde the fprandet and my Tour to doung,\n",
      "\n",
      "And bed:\n",
      "Sitteme,\n",
      "VIQSeresse aas,\n",
      "KI Kevess bong st to dea you ou thirsd Fhind them uem thereren.\n",
      "\n",
      "LALrercepppoancy astard mene the a's thitred and boobelif\n"
     ]
    }
   ],
   "source": [
    "e = Experiment(context_size = 8, num_blocks = 4, num_heads = 8, embedding_size = 8*8)\n",
    "print(e.generate(500))\n",
    "train(e, lr=1e-4, batch_size=64, iterations=2000, iter_eval=100 )\n",
    "print(e.generate(500))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "configuration 256 6 6 384\n",
      "4.44791316986084 4.448210716247559\n",
      "0 4.027475833892822 4.028568267822266\n",
      "1 2.6850509643554688 2.686478614807129\n",
      "2 2.5379507541656494 2.53707218170166\n",
      "3 2.497612237930298 2.4965407848358154\n",
      "4 2.4752283096313477 2.475990056991577\n",
      "5 2.4551048278808594 2.455596923828125\n",
      "6 2.439548969268799 2.4391403198242188\n",
      "7 2.420083522796631 2.4195609092712402\n",
      "8 2.4047975540161133 2.4027047157287598\n",
      "9 2.379061460494995 2.374129056930542\n",
      "10 2.3414764404296875 2.342571496963501\n",
      "11 2.3015737533569336 2.3029565811157227\n",
      "12 2.239624500274658 2.2383382320404053\n",
      "13 2.1889402866363525 2.1866536140441895\n",
      "14 2.1443870067596436 2.1475045680999756\n",
      "15 2.100766181945801 2.0999557971954346\n",
      "16 2.0617241859436035 2.063416004180908\n",
      "17 2.0307254791259766 2.028887987136841\n",
      "18 1.9959670305252075 1.9960229396820068\n",
      "19 1.9612364768981934 1.961883783340454\n",
      "20 1.932071328163147 1.9332457780838013\n",
      "21 1.9072363376617432 1.9050612449645996\n",
      "22 1.8824152946472168 1.8833842277526855\n",
      "23 1.855997085571289 1.8533333539962769\n",
      "24 1.8336833715438843 1.8326287269592285\n",
      "25 1.80907142162323 1.808449625968933\n",
      "26 1.7920321226119995 1.7909818887710571\n",
      "27 1.770053505897522 1.770704746246338\n",
      "28 1.7519965171813965 1.7520475387573242\n",
      "29 1.734154224395752 1.7343670129776\n",
      "30 1.7186895608901978 1.721059799194336\n",
      "31 1.70219087600708 1.6991736888885498\n",
      "32 1.6852563619613647 1.6898084878921509\n",
      "33 1.6716370582580566 1.6741634607315063\n",
      "34 1.6620699167251587 1.6631003618240356\n",
      "35 1.6404821872711182 1.6437784433364868\n",
      "36 1.6359739303588867 1.6301511526107788\n",
      "37 1.6215786933898926 1.617152214050293\n",
      "38 1.608903408050537 1.607116937637329\n",
      "39 1.5974466800689697 1.5991700887680054\n",
      " MEYCANVOMIUSTAMA:\n",
      "AUTIO:\n",
      "As catis deeThar, as fecingssames.\n",
      "Whithes forst!\n",
      "\n",
      "LeAY:\n",
      "Must honer.' 'Lord, coman:\n",
      "How is you bed,\n",
      "So me and son this puspect as.\n",
      "In us, patie they can ambed tos his:\n",
      "Brook, and she good bus we the recence; thing juy sauffer?\n",
      "\n",
      "DUKENCENS:\n",
      "O, condomes for with in be'e hews, so seet: thensomm of aur the,\n",
      "is the here cances, had will conmed alm.\n",
      "\n",
      "MARET:\n",
      "Glime may father, be flowger, be volity\n",
      "DUKE OF VOLE:\n",
      "Was foot shoray's yound\n",
      "A will he give thought indiaked till come of\n"
     ]
    }
   ],
   "source": [
    "e2 = Experiment(context_size = 256, num_blocks = 6, num_heads = 6, embedding_size = 6*64)\n",
    "train(e2, lr=1e-4, batch_size=64, iterations=2000, iter_eval=50 )\n",
    "print(e2.generate(500))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " MFrexADUCKEQUVEY:\n",
      "OLUSAULUS:\n",
      "Whomes, wiSy brABEd Ifid:\n",
      "I chas chame warde mon hom thy condlitie amed.\n",
      "-moe men beadlings ake sewor teek of too wercas?\n",
      "Whe ous, comfick?\n",
      "\n",
      "Provost:\n",
      "Theres's nexore that the a musher! hath we tome\n",
      "And pratent almoon tems,\n",
      "And thost apsty but me flaon, I doth kissitle:\n",
      "By of wiflance do that to the steelf,\n",
      "And despition but roshor aurase bed\n",
      "Shich togs; ark ope; the for proces, foot this fool.\n",
      "\n",
      "FirDIR;:\n",
      "The hath well give him Mastrougher! corve word,\n",
      "And my day thegue soe as all pot our distant.\n",
      "\n",
      "LUCESHENTIO:\n",
      "My wentle find obly leaves to Eche most?\n",
      "Iswake have then reacse my wear:\n",
      "Aho desid wine thougins. Genter's cancil into Rosy\n",
      "bagaliess of the with's the fall of hisping:\n",
      "And how somme tway from grieforgum begar\n",
      "Wich kill isspuit: it saim I am reth\n",
      "Tolson to the brives fevor the ward all at Mostory.\n",
      "\n",
      "Secoust:\n",
      "Here do met tojes ant flace, I knot as acceived;\n",
      "Where we dispose do is and the saddies\n",
      "A some sing is dapious to did this beaw?\n",
      "That a the it I may strice you my specuces!\n",
      "\n",
      "Sirdown:\n",
      "Who, show thou? but but wolt pet tate virget!\n",
      "\n",
      "MENENENIUS:\n",
      "Enk, what up thou desparice 'aures?\n",
      "\n",
      "RUTIAND:\n",
      "So mide do he lichse.\n",
      "\n",
      "KING E3VENcause, all might sayy:\n",
      "Thou custle shy not headon too spray;\n",
      "For coucessil? Pits cause you alf?\n",
      "\n",
      "CAMILLO:\n",
      "I hoot to uputain:\n",
      "I'll you, the sign buth, whick word you my too;\n",
      "On you you kneed a should and dessious?\n",
      "We hough a glave have will flee you him?\n",
      "If Juse, towast! say, but him thought name,\n",
      "The shall if yea, he peakn \n"
     ]
    }
   ],
   "source": [
    "#train(e, lr=1e-4, iterations=2000, iter_eval=100 )\n",
    "print(e2.generate(1500))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5876940488815308 1.5876537561416626\n",
      "0 1.6956408023834229 1.697298526763916\n",
      "1 1.5812041759490967 1.5792243480682373\n",
      "2 1.569296956062317 1.5666412115097046\n",
      "3 1.5594935417175293 1.5636963844299316\n"
     ]
    }
   ],
   "source": [
    "train(e2, lr=1e-4, batch_size=64, iterations=200, iter_eval=50 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.557078242301941 1.5565043687820435\n",
      "0 1.7929167747497559 1.796095848083496\n",
      "1 1.5489294528961182 1.5500853061676025\n",
      "2 1.5443283319473267 1.5471572875976562\n",
      "3 1.5341901779174805 1.5365087985992432\n",
      "4 1.5264430046081543 1.5256478786468506\n",
      "5 1.5187193155288696 1.5185668468475342\n",
      "6 1.5133506059646606 1.5140659809112549\n",
      "7 1.5043244361877441 1.5057636499404907\n",
      "8 1.4962104558944702 1.50107741355896\n",
      "9 1.494091510772705 1.4949402809143066\n",
      "10 1.4884915351867676 1.4876561164855957\n",
      "11 1.4838132858276367 1.4828325510025024\n",
      "12 1.4737396240234375 1.4760366678237915\n",
      "13 1.4673218727111816 1.4679436683654785\n",
      "14 1.4627834558486938 1.4597004652023315\n",
      "15 1.455433964729309 1.4584462642669678\n",
      "16 1.4523550271987915 1.4547147750854492\n",
      "17 1.447634220123291 1.4477453231811523\n",
      "18 1.4383522272109985 1.4419149160385132\n",
      "19 1.434388279914856 1.4319144487380981\n"
     ]
    }
   ],
   "source": [
    "train(e2, lr=1e-4, batch_size=64, iterations=1000, iter_eval=50 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " fitheven torte thers:\n",
      "You offencaffector'd,\n",
      "No, goother pat han of faten lis.\n",
      "\n",
      "S$OVERDWIO:\n",
      "\n",
      "SLANLEY:\n",
      "\n",
      "LADYet we was grage his withaton line,\n",
      "Who he hart they wilt to the date:\n",
      "I all honour! back that the sust mine\n",
      "To lreagely! but cheighn daughters, for her?\n",
      "Why should with my dembation, they un,\n",
      "And grior shall grows, and muster with about change at\n",
      "And there woman: all then I day Poter:\n",
      "And thereful hear nature alonged but of our\n",
      "But birth. Who Plain all sentler lord.\n",
      "Where's this hownour of, our batch, say sicon:\n",
      "But let mest me higheld, to the harl of his\n",
      "sleep-ows, if it that enteech stil the trick.\n",
      "The firstirested me thou deed blust buck:\n",
      "Not thy lovelgge anoptent preace weeporm.\n",
      "Unto comes of thy king from that curfles;\n",
      "To that we To was begeted that murder?\n",
      "Do giving find thus not gives be and will,\n",
      "Or sweak nothres in this house fearl his brotcheds!\n",
      "Mese for how tuth the my for mostanch'd blood,\n",
      "Whose now house from to repenable Duke thy kindled from his,\n",
      "What it shall gend for tell the nothing hath sengar?\n",
      "\n",
      "BRUTUS:\n",
      "Lest on thy nay death?\n",
      "Your broak it, vidol? farethir soon!\n",
      "\n",
      "Citizen:\n",
      "Thy fortune father so in fine old fetch:\n",
      "Not make me, that new duke.\n",
      "And the once sovereign of thee have hire;\n",
      "Cause, if a my baccil'd for with have\n",
      "Throne of bled by with by peet soul west. What my for\n",
      "Let him outer of this,--now, thy since! you word:\n",
      "You my for thrieff, head temblack overdnes,\n",
      "Brother that on I'll have a discatch'd,\n",
      "Like be of York, quike for Tarialts his\n",
      "In make be \n"
     ]
    }
   ],
   "source": [
    "print(e2.generate(1500))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4301226139068604 1.4327268600463867\n",
      "0 1.495746374130249 1.4963414669036865\n",
      "1 1.4183191061019897 1.4199295043945312\n",
      "2 1.4172418117523193 1.4179918766021729\n",
      "3 1.4026403427124023 1.4031051397323608\n",
      "4 1.3996590375900269 1.3954665660858154\n",
      "5 1.3859045505523682 1.3838927745819092\n",
      "6 1.372943639755249 1.374499797821045\n",
      "7 1.3700703382492065 1.36915123462677\n",
      "8 1.3573803901672363 1.363472580909729\n",
      "9 1.3544305562973022 1.352319359779358\n",
      "10 1.3427348136901855 1.3455711603164673\n",
      "11 1.3375816345214844 1.3371108770370483\n",
      "12 1.3319720029830933 1.3297680616378784\n",
      "13 1.3224854469299316 1.322540044784546\n",
      "14 1.3132699728012085 1.3135772943496704\n",
      "15 1.3076298236846924 1.3105628490447998\n",
      "16 1.3033661842346191 1.2979401350021362\n",
      "17 1.298403263092041 1.2947909832000732\n",
      "18 1.2926664352416992 1.2923775911331177\n",
      "19 1.2848608493804932 1.2877528667449951\n"
     ]
    }
   ],
   "source": [
    "train(e2, lr=1e-4, batch_size=64, iterations=2000, iter_eval=100 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " SLLYOUCPEY:\n",
      "N'XINIUS:\n",
      "\n",
      "BESISABELLA:\n",
      "Hell.\n",
      "\n",
      "VAULIA:\n",
      "ANGELUS:\n",
      "HERCHIO:\n",
      "Said Mayorshonous.\n",
      "\n",
      "FLORIZEL.\n",
      "\n",
      "CLAUDIO:\n",
      "That what's you shad be a man sprited you.\n",
      "\n",
      "CORIOLANUS:\n",
      "ES:\n",
      "Chome with. an the our hopes bote home:\n",
      "some, with so me light so do woout I'll wear true,\n",
      "If I must royal lor with Lord satis;\n",
      "And but I thank'd you; let I will it, a varnavour\n",
      "With soft another's but the bed hast.\n",
      "O, concil, who should upon me,\n",
      "A care service to our foremia again?\n",
      "\n",
      "First Keeper:\n",
      "Why, get you go not, you mistress\n",
      "So which hath in this issue.\n",
      "\n",
      "GLOUCESTER:\n",
      "And yet doth Romeo, strange, but by his herm.\n",
      "\n",
      "PETAULINA:\n",
      "On them all declaims when loved the king?\n",
      "\n",
      "LADY CAPULE:\n",
      "No, Perdon, the subject of both the old.\n",
      "\n",
      "LEONTES:\n",
      "Farewell! Madam, afford the traitor-doors it,\n",
      "Most we not so in, good tunder! through thou back,\n",
      "Thou royalt'st thou\n",
      "Think to thy soft muff and thy sacrew:\n",
      "Whom galland when thy longth woful die!\n",
      "\n",
      "MENENIUS:\n",
      "Thou not letters do no success? thou speaking, true!\n",
      "Ortul! place what not thou wast umour this?\n",
      "They in opprote words a dreams to be my ground,\n",
      "Thou shalt hot we man; if I had beggrouse\n",
      "To die. The fast off a Cut fault day!\n",
      "To Henry, and bedy that seems; he prince.\n",
      "And so toward so end him.\n",
      "\n",
      "LEONTES:\n",
      "Art thou, Tranius, his son?\n",
      "\n",
      "Both:\n",
      "As thou take us eye ancient like royal man\n",
      "they shall get hyself we of the love,\n",
      "So, being his aboved mighty chept haste.\n",
      "Thou art is no loved friend a thousand prison:\n",
      "But it, my mind love at accurvity this princely son,\n",
      "Scaruly her no spoor sho\n"
     ]
    }
   ],
   "source": [
    "print(e2.generate(1500))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2768762111663818 1.2778184413909912\n",
      "0 1.303093671798706 1.3015209436416626\n",
      "1 1.2757031917572021 1.2750481367111206\n",
      "2 1.2653851509094238 1.267059326171875\n",
      "3 1.2613242864608765 1.2614907026290894\n",
      "4 1.2557693719863892 1.2551026344299316\n",
      "5 1.2508587837219238 1.2508403062820435\n",
      "6 1.2467156648635864 1.245319128036499\n",
      "7 1.2416040897369385 1.2416107654571533\n",
      "8 1.2325907945632935 1.2322922945022583\n",
      "9 1.233831763267517 1.2325283288955688\n",
      "10 1.2230241298675537 1.2246685028076172\n",
      "11 1.2208529710769653 1.2205132246017456\n",
      "12 1.2142488956451416 1.2160379886627197\n",
      "13 1.2105913162231445 1.2107101678848267\n",
      "14 1.2037389278411865 1.2075015306472778\n",
      "15 1.1991580724716187 1.2012897729873657\n",
      "16 1.1987706422805786 1.1969448328018188\n",
      "17 1.1917442083358765 1.193029522895813\n",
      "18 1.1894736289978027 1.1862218379974365\n",
      "19 1.1826637983322144 1.181326985359192\n",
      " Ris.\n",
      "BESTMAMPSOLO:\n",
      "SovereONGEO:\n",
      "ASA.\n",
      "\n",
      "Fithird SAMPSON:\n",
      "\n",
      "Sir.\n",
      "\n",
      "VOLUMELEO:\n",
      "HESAMPSA:\n",
      "\n",
      "Fithoping inthee, now as thank the behear you him.\n",
      "\n",
      "Provost:\n",
      "Do say:\n",
      "Not noted think one.\n",
      "\n",
      "VOLUMNIA:\n",
      "You shall.\n",
      "\n",
      "Provost:\n",
      "Nor, let your hence, shall be confortation?\n",
      "No, nor never purse in great can marry here,\n",
      "I must be turn'd king's good morrow.\n",
      "\n",
      "VOLUMNIA:\n",
      "You know no grave us of your good sword\n",
      "To so, and you the best out in him,\n",
      "There's some love, by you come on, as if\n",
      "You might not so preverented on her must,\n",
      "The orocloring inworn barman:\n",
      "Were wrong I moved to the Marcius, having\n",
      "Edward hither.\n",
      "\n",
      "HERMIONE:\n",
      "Mark to see your will; and this son much he\n",
      "Romeo some joyman: poor dear him free from him, your\n",
      "six the hand children with very his one perforce\n",
      "on a hepherd's happiness with gone, whilst this head rest,\n",
      "i' Richard the wind tears of any men into the Ele,\n",
      "now I have cold watch him of Edward will appear!\n",
      "For never be boar, we knew I say it is sweets,\n",
      "More stay was in the night, crown'd in the packs,\n",
      "Or being at quitter resept his further.\n",
      "Now, he justice me, and Tybalt's bows in:\n",
      "O, royal limb from thy happy love;\n",
      "Or they best we laid in grating weep\n",
      "Above their receiviers of loving.\n",
      "\n",
      "FLORIZEL:\n",
      "Such as bow my own, sir.\n",
      "\n",
      "All,\n",
      "ESCALUS:\n",
      "\n",
      "ANGORY:\n",
      "Thus your good kensman:\n",
      "How father? shall come to extreme is fagham.\n",
      "\n",
      "Servant:\n",
      "Uncle, let them humbly have been death, by his son\n",
      "with great a payer riped recling for the strange.\n",
      "\n",
      "SAMPSON:\n",
      "I am confessent? 'tis sweet not.\n",
      "\n",
      "SOMESESER:\n",
      "Procure it bear\n"
     ]
    }
   ],
   "source": [
    "train(e2, lr=1e-4, batch_size=64, iterations=2000, iter_eval=100 )\n",
    "print(e2.generate(1500))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Romeo, do you love me?\n",
      "\n",
      "JULVO.\n",
      "\n",
      "FiLLORord:\n",
      "AUFIDIUS:\n",
      "Ere 'VI re her fame; lord:\n",
      "in gene'er only, grim.\n",
      "\n",
      "JULIET:\n",
      "'Fit is Pray your best, thou shalt be my kind.\n",
      "\n",
      "VALERIA:\n",
      "\n",
      "VOLUMNIA:\n",
      "Too quencest her sworn and same o's a?\n",
      "\n",
      "ROMEO:\n",
      "'Tis both my false; can be it not sound.\n",
      "\n",
      "LRORD OF SANLEY:\n",
      "Then jutst my handed is fair's as thing;\n",
      "Not a bunchless, Norfolk, look to thee: he haman,\n",
      "For their shocks me and their broaks: ah, look\n",
      "This gravers bear in sounds all winessing\n",
      "Things Warwick and think'd the rebellasts of Richmond?\n",
      "\n",
      "Server:\n",
      "Unbuck, brother,\n",
      "Scorn Hastings. Nor this true hand must write!\n",
      "To see her drop aggain, therest be'n mouths leave,\n",
      "And that thou wert bone,\n",
      "For no breathe, 'twere no of time sitting\n",
      "Which Of the heart of thy son wit's life\n",
      "Shall be a throne-solding how to they abroad:\n",
      "'Tis have been her beard,\n",
      "I will not with with the same may word them:\n",
      "And inhen the way\n",
      "To Bolingbroke of his loit borrow.\n",
      "\n",
      "ROMEO:\n",
      "He is a nature of hands for this sovereign's\n",
      "For storer than resh reproyaring and his arms:\n",
      "And his dead 'mought his at engry in a gall\n",
      "That choose a fellow for near'd prance fines\n",
      "Upon him that have done, and I him to their\n",
      "This searing-everal have and hope his submissbers\n",
      "Which he hated the stabb'd of this king,\n",
      "Edward, is both a provilegred of his prodiging\n",
      "From the match here thee to more than act on it.\n",
      "This is against for they be widows again,\n",
      "But her forbid the instruct the nights upon.\n",
      "\n",
      "KING EDWARD IV:\n",
      "Then appearell appoit and saints and men,\n",
      "Whom hence was hanging her: what \n"
     ]
    }
   ],
   "source": [
    "print(e2.generate(1500, \"Romeo, do you love me?\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "huggingface",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
